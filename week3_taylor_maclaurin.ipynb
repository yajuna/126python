{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f4f7d9",
   "metadata": {},
   "source": [
    "# We have seen power series and their interval of convergence. We look at the convergence to the function by the power expansion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages, and conventional abbrev.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## for math display\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4390dd0",
   "metadata": {},
   "source": [
    "## Recall $\\sum^{\\infty}_{n=0}x^n=\\frac{1}{1-x}$, for $|x|<1$. We show that $\\sum^{N}_{n=0}x^n\\approx\\frac{1}{1-x}$, and the approximation is better when $N$ is bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the geometric power series \n",
    "\n",
    "f_exact = lambda x: 1/(1-x)\n",
    "f_approx = lambda x, N: sum([x**n for n in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6437ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "\n",
    "x = np.linspace(-0.9, 0.9, 5000)\n",
    "\n",
    "f_ex = f_exact(x)\n",
    "f_N =f_approx(x,N)\n",
    "\n",
    "error = f_N - f_ex\n",
    "errorMax = np.max(np.abs(error))\n",
    "print('The max error is', errorMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "fig1 = plt.subplot(1,2,1)\n",
    "plt.plot(x,f_ex,'b.',markersize=3)\n",
    "plt.plot(x,f_N,'r.',markersize=3)\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('Function and power approximation')\n",
    "\n",
    "fig2 = plt.subplot(1,2,2)\n",
    "plt.plot(x,error,'b.',markersize=3)\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('Max Error is '+str(errorMax))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285907bc",
   "metadata": {},
   "source": [
    "## Just for fun, we plot the function (f_exact) and the series (f_approx) outside of the interval of convergence.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1.1, 3.1, 5000)\n",
    "\n",
    "f_ex = f_exact(x)\n",
    "f_N =f_approx(x,N)\n",
    "\n",
    "error = f_N - f_ex\n",
    "errorMax = np.max(np.abs(error))\n",
    "print('The max error outside of interval of convergence is', errorMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0404d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "fig1 = plt.subplot(1,2,1)\n",
    "plt.plot(x,f_ex,'b.',markersize=3)\n",
    "plt.plot(x,f_N,'r.',markersize=3)\n",
    "plt.xlim(1.1, 1.5)\n",
    "plt.ylim(-150,5000)\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('Function and power approximation')\n",
    "\n",
    "fig2 = plt.subplot(1,2,2)\n",
    "plt.plot(x,error,'b.',markersize=3)\n",
    "# plt.xlim(1.1, 1.5)\n",
    "# plt.ylim(0,5000)\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('Max Error is '+str(errorMax))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1bb17",
   "metadata": {},
   "source": [
    "## Now we look at the error terms as $N$ becomes bigger. We predict that the error will become smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-0.9, 0.9, 5000)\n",
    "\n",
    "errorMax = []\n",
    "\n",
    "l = [i for i in np.arange(0,500,5)]\n",
    "\n",
    "for N in l:\n",
    "    f_ex = f_exact(x)\n",
    "    f_N =f_approx(x,N)\n",
    "    error = f_N - f_ex\n",
    "    errorMax.append(np.max(np.abs(error)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(10, 10))\n",
    "plt.plot(l,errorMax,'b.',markersize=3)\n",
    "plt.ylim(-0.1, 6.001)\n",
    "plt.xlim(l[0],l[-1])\n",
    "plt.xlabel('Number of terms in Taylor Polynomials')\n",
    "plt.ylabel('Max Error')# is '+str(errorMax))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a897b",
   "metadata": {},
   "source": [
    "## We know the Maclaurin series of $e^x$ is $e^x=1 + x + x^2/2! + x^3/3! + \\dots + x^n/n!+ ...$. With $x=1$, we approximate the value of $e$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e4b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Maclaurin polynomial of e^x\n",
    "\n",
    "e_approx = lambda x, N: sum([x**n/np.math.factorial(n) for n in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc26a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, N = 1, 50\n",
    "e_comp = e_approx(x,N)\n",
    "print('Approximate value of e with N = ', N, ' is ', e_comp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
